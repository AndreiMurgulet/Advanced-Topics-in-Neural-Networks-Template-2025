## Lab 2

***


Lab Notebook

1. [Complex Yet Simple Training Pipeline](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/advanced_pytorch/ComplexYetSimpleTrainingPipeline.ipynb)
2. [Inference Optimization And TTA](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/advanced_pytorch/InferenceOptimizationAndTTA.ipynb)

The exercises from these notebook are a good preparation for homework 2, and can help you acquire MLOps or Data Science skills.

<details><summary>Bonus points</summary>
You will get bonus points if you do all 4 exercises from "Complex Yet Simple Training Pipeline" and submit them until Lab 4.

You will get bonus points if you do all MLOps exercises from "Inference Optimization And TTA".
</details>

***

Homework 2: https://www.kaggle.com/t/5fe1947f27b743beb65e005fd709cf79

***

For self-study (for students who want to pass):
* Skim over the 2 references: LeCun (98) and Keskar (2017).
***


Advanced (for students who want to learn more):
* Learn how to choose hyperparameters and the influence of batch size:
  * [Gradient Based Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) (LeCun, 98)
  * [On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima](https://arxiv.org/abs/1609.04836) (Keskar, 2017)
